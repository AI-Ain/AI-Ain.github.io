<b>Data science portfolio by Dileep.A</b>

This portfolio is a compilation of notebooks which I created for data analysis or for exploration of machine learning algorithms. A separate category is for separate projects.

<b>Stand-alone projects.,</b>
Handwritten digit recognition
This is my own project using image recognition methods in practice. This is a site (also works on mobile) where user can draw a digit, and machine learning models (FNN and CNN) will try to recognize it. After than models can use the drawn digit for training to improve their accuracy. Live version is here. The code can be found here.

<b>Kaggle kernels.</b>

<b>Home Credit Default Risk</b>
Home Credit Bank offers a challenge of credit scoring. There is a lot of data about applicants and their previous behavior. The code can be found here.

<b>Movie Review Sentiment Analysis</b>
Some time ago Kaggle has launched several “remakes” of old competitions. It means that datasets are the same, but now we are offered an opportunity to simply explore the data and create kernels with new methods. One of these competitions is sentiment analysis of Rotten Tomatoes dataset with 5 classes (negative, somewhat negative, neutral, somewhat positive, positive). I have created a kernel with EDA and modern NN architecture: LSTM-CNN. Currently this kernel shows the 5th result of leaderboard.

<b>Data Science for Good: Center for Policing Equity</b>
This dataset was provided by The Center for Policing Equity. They hope that kagglers will help to create better models, find some unique insights and improve geo-analytics. In my kernel I try to do such things.

<b>Classification problems.</b>
Titanic: Machine Learning from Disaster
Azure ML Studio.

Titanic: Machine Learning from Disaster is a knowledge competition on Kaggle. Many people started practicing in machine learning with this competition, so did I. This is a binary classification problem: based on information about Titanic passengers we predict whether they survived or not. General description and data are available on Kaggle. Titanic dataset provides interesting opportunities for feature engineering.

<b>Regression problems.</b>
House Prices: Advanced Regression Techniques
Github nbviewer

House Prices: Advanced Regression Techniques is a knowledge competition on Kaggle. This is a regression problem: based on information about houses we predict their prices. General description and data are available on Kaggle. The dataset has a lot of features and many missing values. This gives interesting possibilities for feature transformation and data visualization.

Loan Prediction
Github nbviewer

Loan Prediction is a knowledge and learning hackathon on Analyticsvidhya. Dream Housing Finance company deals in home loans. Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. Based on customer’s information we predict whether they should receive a loan or not. General description and data are available on Analyticsvidhya.

<b>Natural language processing.</b>
Bag of Words Meets Bags of Popcorn
Github nbviewer

Bag of Words Meets Bags of Popcorn is a sentimental analysis problem. Based on texts of reviews we predict whether they are positive or negative. General description and data are available on Kaggle. The data provided consists of raw reviews and class (1 or 2), so the main part is cleaning the texts.

NLP with Python: exploring Fate/Zero
Github nbviewer

Natural language processing in machine learning helps to accomplish a variety of tasks, one of which is extracting information from texts. This notebook is an overview of several text exploration methods using English translation of Japanese light novel “Fate/Zero” as an example.

NLP. Text generation with Markov chains
Github nbviewer

This notebook shows how a new text can be generated based on a given corpus using an idea of Markov chains. I start with simple first-order chains and with each step improve model to generate better text.

NLP. Text summarization
Github nbviewer

This notebook shows how text can be summarized choosing several most important sentences from the text. I explore various methods of doing this based on a news article.

<b>Clustering</b>
Clustering with KMeans
Github nbviewer

Clustering is an approach to unsupervised machine learning. Clustering with KMeans is one of algorithms of clustering. in this notebook I’ll demonstrate how it works. Data used is about various types of seeds and their parameters. It is available here.

Neural networks
Feedforward neural network with regularization
Github nbviewer

This is a simple example of feedforward neural network with regularization. It is based on Andrew Ng’s lectures on Coursera. I used data from Kaggle’s challenge “Ghouls, Goblins, and Ghosts… Boo!”, it is available here.

Data exploration and analysis
Telematic data
Github nbviewer

I have a dataset with telematic information about 10 cars driving during one day. I visualise data, search for insights and analyse the behavior of each driver. I can’t share the data, but here is the notebook. I want to notice that folium map can’t be rendered by native github, but nbviewer.jupyter can do it.

Recommendation systems.
Collaborative filtering
Github nbviewer

Recommenders are systems, which predict ratings of users for items. There are several approaches to build such systems and one of them is Collaborative Filtering. This notebook shows several examples of collaborative filtering algorithms.

